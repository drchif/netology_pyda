{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from sklearn.datasets.samples_generator import make_classification\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from pprint import pprint\n",
    "from random import randrange\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('zoo.csv',\n",
    "                      names=['animal_name','hair','feathers','eggs','milk',\n",
    "                                                   'airbone','aquatic','predator','toothed','backbone',\n",
    "                                                  'breathes','venomous','fins','legs','tail','domestic','catsize','class',])\n",
    "dataset=dataset.drop('animal_name',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hair</th>\n",
       "      <th>feathers</th>\n",
       "      <th>eggs</th>\n",
       "      <th>milk</th>\n",
       "      <th>airbone</th>\n",
       "      <th>aquatic</th>\n",
       "      <th>predator</th>\n",
       "      <th>toothed</th>\n",
       "      <th>backbone</th>\n",
       "      <th>breathes</th>\n",
       "      <th>venomous</th>\n",
       "      <th>fins</th>\n",
       "      <th>legs</th>\n",
       "      <th>tail</th>\n",
       "      <th>domestic</th>\n",
       "      <th>catsize</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   hair  feathers  eggs  milk  airbone  aquatic  predator  toothed  backbone  \\\n",
       "0     1         0     0     1        0        0         1        1         1   \n",
       "1     1         0     0     1        0        0         0        1         1   \n",
       "2     0         0     1     0        0        1         1        1         1   \n",
       "3     1         0     0     1        0        0         1        1         1   \n",
       "4     1         0     0     1        0        0         1        1         1   \n",
       "\n",
       "   breathes  venomous  fins  legs  tail  domestic  catsize  class  \n",
       "0         1         0     0     4     0         0        1      1  \n",
       "1         1         0     0     4     1         0        1      1  \n",
       "2         0         0     1     0     1         0        0      4  \n",
       "3         1         0     0     4     0         0        1      1  \n",
       "4         1         0     0     4     1         0        1      1  "
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def entropy(target_col):\n",
    "    \"\"\"\n",
    "    Считаем энтропийный критерий.\n",
    "    Параметром функции является target_col - целевой столбец по которому нужно посчитать критерий\n",
    "    \"\"\"\n",
    "    #узнаем уникальные элементы и их количество в целевом столбце\n",
    "    elements,counts = np.unique(target_col,return_counts = True)\n",
    "    #считаем критерий энтропии в цикле\n",
    "    entropy = np.sum([(-counts[i]/np.sum(counts))*np.log2(counts[i]/np.sum(counts)) for i in range(len(elements))])\n",
    "    return entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def InfoGain(data,split_attribute_name,target_name='class'):\n",
    "    \"\"\"\n",
    "    Считаем функционал качества, 3 параметра:\n",
    "    1. data - входной датасет\n",
    "    2. split_attribute_name - объект для которого считаем IG\n",
    "    3. target_name - целевая функция. по дефалту ставим class (под датасет)\n",
    "    \"\"\"    \n",
    "    #Считаем критерии для всего дата сета (тут можно сделать \"переключалку\" в зависимости от критерия)\n",
    "    total_entropy = entropy(data[target_name])\n",
    "    \n",
    "    ##Calculate the entropy of the dataset\n",
    "    \n",
    "    #Считаем значения для сплита \n",
    "    vals,counts= np.unique(data[split_attribute_name],return_counts=True)\n",
    "    \n",
    "    #Считаем взвешеный критерий\n",
    "    Weighted_Entropy = np.sum([(counts[i]/np.sum(counts))*entropy(data.where(data[split_attribute_name]==vals[i]).dropna()[target_name]) for i in range(len(vals))])\n",
    "    \n",
    "    #Считаем IG\n",
    "    Information_Gain = total_entropy - Weighted_Entropy\n",
    "    return Information_Gain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ID3(data,originaldata,features,target_attribute_name='class',parent_node_class = None):\n",
    "    \"\"\"\n",
    "    1. data - исходный датасет. При первом запуске равен исходному датасету.\n",
    "    2. originaldata - исходный датасет. Нужен что бы если первый пункт пернул пусто\n",
    "    3. features - пространство признаков датасета. Нужно для рекурсивного вызова функции - разделение по веткам\n",
    "    4. target_attribute_name - целевой атрибут\n",
    "    5. parent_node_class - значение целевого атрибута ветки. нужно для рекурсивного вызова - когда ветка кончилась и мы хотим вернуть лист\n",
    "    \"\"\"   \n",
    "    #Определяем критерий остановки -> Если что-то из этого выполнено, то возвращаем лист\n",
    "    \n",
    "    #Если все target_values одинаковые, то возвращаем это значение\n",
    "    if len(np.unique(data[target_attribute_name])) <= 1:\n",
    "        return np.unique(data[target_attribute_name])[0]\n",
    "    \n",
    "    #Если датасет пустой, то значение целевого атрибута из исходного датасета\n",
    "    elif len(data)==0:\n",
    "        return np.unique(originaldata[target_attribute_name])[np.argmax(np.unique(originaldata[target_attribute_name],return_counts=True)[1])]\n",
    "    \n",
    "    # Если feature пустое, то вернуть значение из родительсткого узла - parent_node_class\n",
    "    \n",
    "    elif len(features) ==0:\n",
    "        return parent_node_class\n",
    "    \n",
    "    #Если ничего из вышеперечисленного не выполняется, то строим дерево.\n",
    "    \n",
    "    else:\n",
    "        #Ставим значение по умолчанию для этого узла \n",
    "        parent_node_class = np.unique(data[target_attribute_name])[np.argmax(np.unique(data[target_attribute_name],return_counts=True)[1])]\n",
    "        \n",
    "        #Идем лушее features для разделения датасета\n",
    "        item_values = [InfoGain(data,feature,target_attribute_name) for feature in features]#Знаение IG для объектов датасета\n",
    "        best_feature_index = np.argmax(item_values)\n",
    "        best_feature = features[best_feature_index]\n",
    "        \n",
    "        #Создает дерево. Корень best_feature с макс IG при первом вызове\n",
    "        tree = {best_feature:{}}\n",
    "        \n",
    "        \n",
    "        #Убираем лучшее best_feature по IG из features\n",
    "        features = [i for i in features if i != best_feature]\n",
    "        \n",
    "        #Спускаемся от корневой ветки по всем возможным features\n",
    "        \n",
    "        for value in np.unique(data[best_feature]):\n",
    "            value = value\n",
    "            #Разделим датасет по features с наибольшим IG = создаем sub_data\n",
    "            sub_data = data.where(data[best_feature] == value).dropna()\n",
    "            \n",
    "            #Вызываем ID3 для каждого sub_data - пошла рекурсия\n",
    "            subtree = ID3(sub_data,dataset,features,target_attribute_name,parent_node_class)\n",
    "            \n",
    "            #Добавляем ветки из sub_data под корень\n",
    "            tree[best_feature][value] = subtree\n",
    "            \n",
    "        return(tree)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict(query,tree,default = 1):\n",
    "    \"\"\"\n",
    "    Прогноз\n",
    "    Рекурсивный спуск по дереву в поисках ответа - ветка или лист\n",
    "    \"\"\"\n",
    "    for key in list(query.keys()):\n",
    "        if key in list(tree.keys()):\n",
    "            try:\n",
    "                result = tree[key][query[key]] \n",
    "            except:\n",
    "                return default\n",
    "  \n",
    "            result = tree[key][query[key]]\n",
    "            if isinstance(result,dict):\n",
    "                return predict(query,result)\n",
    "\n",
    "            else:\n",
    "                return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(dataset):\n",
    "    \"\"\"\n",
    "    Разделяем датасет на тренировочные и тестовые данные\n",
    "    \"\"\"\n",
    "    training_data = dataset.iloc[:80].reset_index(drop=True)\n",
    "    testing_data = dataset.iloc[80:].reset_index(drop=True)\n",
    "    return training_data,testing_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test(data,tree):\n",
    "    #СОздаем запрос, удалив целевую функцию и переведем в словарик\n",
    "    queries = data.iloc[:,:-1].to_dict(orient = \"records\")\n",
    "    \n",
    "    #Пустой датафрейм с предсказанием\n",
    "    predicted = pd.DataFrame(columns=[\"predicted\"]) \n",
    "    \n",
    "    #Считаем accuracy\n",
    "    for i in range(len(data)):\n",
    "        predicted.loc[i,\"predicted\"] = predict(queries[i],tree,1.0) \n",
    "    print('The prediction accuracy is: ',(np.sum(predicted[\"predicted\"] == data['class'])/len(data))*100,'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = train_test_split(dataset)[0]\n",
    "testing_data = train_test_split(dataset)[1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'legs': {0: {'fins': {0.0: {'toothed': {0.0: 7.0, 1.0: 3.0}},\n",
      "                       1.0: {'eggs': {0.0: 1.0, 1.0: 4.0}}}},\n",
      "          2: {'hair': {0.0: 2.0, 1.0: 1.0}},\n",
      "          4: {'hair': {0.0: {'toothed': {0.0: 7.0, 1.0: 5.0}}, 1.0: 1.0}},\n",
      "          6: {'aquatic': {0.0: 6.0, 1.0: 7.0}},\n",
      "          8: 7.0}}\n",
      "The prediction accuracy is:  85.71428571428571 %\n"
     ]
    }
   ],
   "source": [
    "tree = ID3(training_data,training_data,training_data.columns[:-1])\n",
    "pprint(tree)\n",
    "test(testing_data,tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_features = df.iloc[:80,:-1]\n",
    "test_features = df.iloc[80:,:-1]\n",
    "train_targets = df.iloc[:80,-1]\n",
    "test_targets = df.iloc[80:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tree = DecisionTreeClassifier(criterion = 'entropy').fit(train_features,train_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prediction = tree.predict(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prediction accuracy is:  80.0 %\n"
     ]
    }
   ],
   "source": [
    "print(\"The prediction accuracy is: \",tree.score(test_features,test_targets)*100,\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Другой вариант решения - можно не смотреть"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset_arr = dataset.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Calculate the Gini index for a split dataset\n",
    "def gini_index(groups, classes):\n",
    "    # count all samples at split point\n",
    "    n_instances = float(sum([len(group) for group in groups]))\n",
    "    # sum weighted Gini index for each group\n",
    "    gini = 0.0\n",
    "    for group in groups:\n",
    "        size = float(len(group))\n",
    "        # avoid divide by zero\n",
    "        if size == 0:\n",
    "            continue\n",
    "        score = 0.0\n",
    "        # score the group based on the score for each class\n",
    "        for class_val in classes:\n",
    "            p = [row[-1] for row in group].count(class_val) / size\n",
    "            score += p * p\n",
    "        # weight the group score by its relative size\n",
    "        gini += (1.0 - score) * (size / n_instances)\n",
    "    return gini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Split a dataset based on an attribute and an attribute value\n",
    "def test_split(index, value, dataset):\n",
    "    left, right = list(), list()\n",
    "    for row in dataset:\n",
    "        if row[index] < value:\n",
    "            left.append(row)\n",
    "        else:\n",
    "            right.append(row)\n",
    "    return left, right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split: [X4 < 1.000]\n"
     ]
    }
   ],
   "source": [
    "split = get_split(dataset_arr)#data_\n",
    "print('Split: [X%d < %.3f]' % ((split['index']+1), split['value']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a terminal node value\n",
    "def to_terminal(group):\n",
    "    outcomes = [row[-1] for row in group]\n",
    "    return max(set(outcomes), key=outcomes.count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create child splits for a node or make terminal\n",
    "def split(node, max_depth, min_size, depth):\n",
    "    left, right = node['groups']\n",
    "    del(node['groups'])\n",
    "    # check for a no split\n",
    "    if not left or not right:\n",
    "        node['left'] = node['right'] = to_terminal(left + right)\n",
    "        return\n",
    "    # check for max depth\n",
    "    if depth >= max_depth:\n",
    "        node['left'], node['right'] = to_terminal(left), to_terminal(right)\n",
    "        return\n",
    "    # process left child\n",
    "    if len(left) <= min_size:\n",
    "        node['left'] = to_terminal(left)\n",
    "    else:\n",
    "        node['left'] = get_split(left)\n",
    "        split(node['left'], max_depth, min_size, depth+1)\n",
    "    # process right child\n",
    "    if len(right) <= min_size:\n",
    "        node['right'] = to_terminal(right)\n",
    "    else:\n",
    "        node['right'] = get_split(right)\n",
    "        split(node['right'], max_depth, min_size, depth+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Build a decision tree\n",
    "def build_tree(train, max_depth, min_size):\n",
    "    root = get_split(train)\n",
    "    split(root, max_depth, min_size, 1)\n",
    "    return root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Print a decision tree\n",
    "def print_tree(node, depth=0):\n",
    "    if isinstance(node, dict):\n",
    "        print('%s[X%d < %.3f]' % ((depth*' ', (node['index']+1), node['value'])))\n",
    "        print_tree(node['left'], depth+1)\n",
    "        print_tree(node['right'], depth+1)\n",
    "    else:\n",
    "        print('%s[%s]' % ((depth*' ', node)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[X4 < 1.000]\n",
      " [X2 < 1.000]\n",
      "  [X12 < 1.000]\n",
      "   [X9 < 1.000]\n",
      "    [X5 < 1.000]\n",
      "     [7]\n",
      "     [6]\n",
      "    [3]\n",
      "   [X1 < 0.000]\n",
      "    [4]\n",
      "    [4]\n",
      "  [X1 < 0.000]\n",
      "   [2]\n",
      "   [2]\n",
      " [X1 < 1.000]\n",
      "  [1]\n",
      "  [X1 < 1.000]\n",
      "   [1]\n",
      "   [1]\n"
     ]
    }
   ],
   "source": [
    "tree = build_tree(dataset_arr, 5, 10)#data_\n",
    "print_tree(tree)\n",
    "#print(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(node, row):\n",
    "    if row[node['index']] < node['value']:\n",
    "        if isinstance(node['left'], dict):\n",
    "            return predict(node['left'], row)\n",
    "        else:\n",
    "            return node['left']\n",
    "    else:\n",
    "        if isinstance(node['right'], dict):\n",
    "            return predict(node['right'], row)\n",
    "        else:\n",
    "            return node['right']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification and Regression Tree Algorithm\n",
    "def decision_tree(train, test, max_depth, min_size):\n",
    "    tree = build_tree(train, max_depth, min_size)\n",
    "    predictions = list()\n",
    "    for row in test:\n",
    "        prediction = predict(tree, row)\n",
    "        predictions.append(prediction)\n",
    "    return(predictions)\n",
    "\n",
    "# Calculate accuracy percentage\n",
    "def accuracy_metric(actual, predicted):\n",
    "    correct = 0\n",
    "    for i in range(len(actual)):\n",
    "        if actual[i] == predicted[i]:\n",
    "            correct += 1\n",
    "return correct / float(len(actual)) * 100.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "max_depth = 5\n",
    "min_size = 10\n",
    "ttt = decision_tree(dataset_arr[:80], dataset_arr[80:,:-1], max_depth, min_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset_arr[80:,-1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80.95238095238095"
      ]
     },
     "execution_count": 395,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_metric(dataset_arr[80:,-1:], ttt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Тест второго алгоритма с генерированным датосетом"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x, y = make_classification(n_samples=100, random_state=20, n_informative=2, n_features=2, n_redundant = 0\n",
    "                          )\n",
    "m, n = np.shape(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.c_[ np.ones(m), x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.582773</td>\n",
       "      <td>0.684918</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-2.052907</td>\n",
       "      <td>0.401974</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.268808</td>\n",
       "      <td>-1.330203</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.666392</td>\n",
       "      <td>2.863175</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.907552</td>\n",
       "      <td>0.384912</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     a        x1        x2    y\n",
       "0  1.0 -1.582773  0.684918  0.0\n",
       "1  1.0 -2.052907  0.401974  0.0\n",
       "2  1.0  1.268808 -1.330203  1.0\n",
       "3  1.0  0.666392  2.863175  0.0\n",
       "4  1.0  0.907552  0.384912  1.0"
      ]
     },
     "execution_count": 400,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_ = np.c_[x,y]\n",
    "df = pd.DataFrame(data=data_)\n",
    "df.columns = ['a','x1','x2','y']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80.0"
      ]
     },
     "execution_count": 401,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_depth = 5\n",
    "min_size = 10\n",
    "ttt = decision_tree(data_[:80], data_[80:,:-1], max_depth, min_size)\n",
    "accuracy_metric(data_[80:,-1:], ttt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[X2 < 0.418]\n",
      " [X2 < -0.123]\n",
      "  [X3 < 1.443]\n",
      "   [X1 < 1.000]\n",
      "    [0.0]\n",
      "    [0.0]\n",
      "   [0.0]\n",
      "  [0.0]\n",
      " [X3 < 2.046]\n",
      "  [X3 < -3.587]\n",
      "   [0.0]\n",
      "   [X2 < 0.535]\n",
      "    [1.0]\n",
      "    [X2 < 1.193]\n",
      "     [1.0]\n",
      "     [1.0]\n",
      "  [0.0]\n"
     ]
    }
   ],
   "source": [
    "tree = build_tree(data_, max_depth, min_size)\n",
    "print_tree(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Вот это я уже не смог разобрать"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Split a dataset into k folds\n",
    "def cross_validation_split(dataset, n_folds):\n",
    "\tdataset_split = list()\n",
    "\tdataset_copy = list(dataset)\n",
    "\tfold_size = int(len(dataset) / n_folds)\n",
    "\tfor i in range(n_folds):\n",
    "\t\tfold = list()\n",
    "\t\twhile len(fold) < fold_size:\n",
    "\t\t\tindex = randrange(len(dataset_copy))\n",
    "\t\t\tfold.append(dataset_copy.pop(index))\n",
    "\t\tdataset_split.append(fold)\n",
    "\treturn dataset_split\n",
    "\n",
    "# Evaluate an algorithm using a cross validation split\n",
    "def evaluate_algorithm(dataset, algorithm, n_folds, *args):\n",
    "\tfolds = cross_validation_split(dataset, n_folds)\n",
    "\tscores = list()\n",
    "\tfor fold in folds:\n",
    "\t\ttrain_set = list(folds)\n",
    "\t\ttrain_set.remove(fold)\n",
    "\t\ttrain_set = sum(train_set, [])\n",
    "\t\ttest_set = list()\n",
    "\t\tfor row in fold:\n",
    "\t\t\trow_copy = list(row)\n",
    "\t\t\ttest_set.append(row_copy)\n",
    "\t\t\trow_copy[-1] = None\n",
    "\t\tpredicted = algorithm(train_set, test_set, *args)\n",
    "\t\tactual = [row[-1] for row in fold]\n",
    "\t\taccuracy = accuracy_metric(actual, predicted)\n",
    "\t\tscores.append(accuracy)\n",
    "\treturn scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate algorithm\n",
    "n_folds = 17\n",
    "max_depth = 5\n",
    "min_size = 10\n",
    "scores = evaluate_algorithm(dataset_arr, decision_tree, n_folds, max_depth, min_size)#data_\n",
    "print('Scores: %s' % scores)\n",
    "print('Mean Accuracy: %.3f%%' % (sum(scores)/float(len(scores))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Доп материалы\n",
    "# https://www.python-course.eu/Decision_Trees.php\n",
    "# https://www.machinelearningmastery.ru/implement-decision-tree-algorithm-scratch-python/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
